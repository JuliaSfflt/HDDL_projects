{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "561b28d7-202f-42c6-a4ce-75822454f966",
   "metadata": {},
   "source": [
    "### <left> High-Dimensional Deep Learning - 5A\n",
    "## <center>*Mini-project n° 3 – SSL for Anomaly Detection*</center>\n",
    "### <center>2024-2025</center>\n",
    "<div style=\"text-align: right;\">\n",
    "    <b>Project 3/4</b><br>\n",
    "<div style=\"text-align: left;\">\n",
    "<b>Noms :</b> Maïmouna Gadji, Phuc-Luan Nguyen, Maddie Perez et Julia Soufflet<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1a2420-45fa-4e7e-b95e-33621a17d6b4",
   "metadata": {},
   "source": [
    "### Objectif : \n",
    "\n",
    "L'objectif de ce projet est de "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7f4a39c-ac39-433a-8431-9ca1337038e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f69ddd8f-668c-4f9f-8da3-cb5121c499e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training images\n",
    "pathb=\"./MVTec_AD/bottle\"\n",
    "pathh = \"./MVTec_AD/hazelnut\"\n",
    "pathc = \"./MVTec_AD/capsule\"\n",
    "patht = \"./MVTec_AD/toothbrush\"\n",
    "pathw = \"./engine_wiring\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70f689b7-36b4-4bf3-ac50-3b5e81d3f10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training images\n",
    "train_filenames_bottle = os.listdir(pathb + \"/train/good\")\n",
    "train_filenames_hazelnut = os.listdir(pathh + \"/train/good\")\n",
    "train_filenames_capsule = os.listdir(pathc + \"/train/good\")\n",
    "train_filenames_toothbrush = os.listdir(patht + \"/train/good\")\n",
    "train_filenames_W = os.listdir(pathw + \"/train/good\")\n",
    "#Création des labels\n",
    "train_categories_B = []\n",
    "for filename in train_filenames_bottle:\n",
    "    train_categories_B.append(0)\n",
    "\n",
    "train_categories_H = []\n",
    "for filename in train_filenames_hazelnut:\n",
    "    train_categories_H.append(0)\n",
    "\n",
    "train_categories_C = []\n",
    "for filename in train_filenames_capsule:\n",
    "    train_categories_C.append(0)\n",
    "\n",
    "train_categories_T = []\n",
    "for filename in train_filenames_toothbrush:\n",
    "    train_categories_T.append(0)\n",
    "\n",
    "train_categories_W = []\n",
    "for filename in train_filenames_W:\n",
    "    train_categories_W.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eaf0857-5e51-458a-abc3-76443de083a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reorganize_images_good(source_dirs, target_dir):\n",
    "    \"\"\"\n",
    "    Cette fonction regroupe les images des différents dossiers (good et défauts) et les renomme avec des noms uniques.\n",
    "    \n",
    "    :param source_dirs: Liste des chemins vers les dossiers à traiter (good et les dossiers défauts)\n",
    "    :param target_dir: Dossier où toutes les images seront regroupées et renommées\n",
    "    \"\"\"\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)  # Crée le dossier cible s'il n'existe pas\n",
    "    \n",
    "    count = 1  # Compteur pour nommer les fichiers de manière unique\n",
    "\n",
    "    # Parcours chaque dossier dans la liste source_dirs\n",
    "    for source_dir in source_dirs:\n",
    "        for filename in os.listdir(source_dir):\n",
    "            file_path = os.path.join(source_dir, filename)\n",
    "            \n",
    "            # Vérifie si c'est un fichier image (vous pouvez étendre les types de fichiers si nécessaire)\n",
    "            if os.path.isfile(file_path) and filename.endswith(('.png')):\n",
    "                # Nouveau nom basé sur le compteur\n",
    "                new_name = f\"good{str(count).zfill(3)}.png\"  # 001.jpg, 002.jpg, etc.\n",
    "                target_path = os.path.join(target_dir, new_name)\n",
    "                \n",
    "                # Copie le fichier vers le dossier cible avec le nouveau nom\n",
    "                shutil.copy(file_path, target_path)\n",
    "                \n",
    "                # Incrémente le compteur pour le prochain fichier\n",
    "                count += 1\n",
    "\n",
    "def reorganize_images_default(source_dirs, target_dir):\n",
    "    \"\"\"\n",
    "    Cette fonction regroupe les images des différents dossiers (good et défauts) et les renomme avec des noms uniques.\n",
    "    \n",
    "    :param source_dirs: Liste des chemins vers les dossiers à traiter (good et les dossiers défauts)\n",
    "    :param target_dir: Dossier où toutes les images seront regroupées et renommées\n",
    "    \"\"\"\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)  # Crée le dossier cible s'il n'existe pas\n",
    "    \n",
    "    count = 1  # Compteur pour nommer les fichiers de manière unique\n",
    "\n",
    "    # Parcours chaque dossier dans la liste source_dirs\n",
    "    for source_dir in source_dirs:\n",
    "        for filename in os.listdir(source_dir):\n",
    "            file_path = os.path.join(source_dir, filename)\n",
    "            \n",
    "            # Vérifie si c'est un fichier image (vous pouvez étendre les types de fichiers si nécessaire)\n",
    "            if os.path.isfile(file_path) and filename.endswith(('.png')):\n",
    "                # Nouveau nom basé sur le compteur\n",
    "                new_name = f\"default{str(count).zfill(3)}.png\"  # 001.jpg, 002.jpg, etc.\n",
    "                target_path = os.path.join(target_dir, new_name)\n",
    "                \n",
    "                # Copie le fichier vers le dossier cible avec le nouveau nom\n",
    "                shutil.copy(file_path, target_path)\n",
    "                \n",
    "                # Incrémente le compteur pour le prochain fichier\n",
    "                count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbef6d92-dd33-4646-a054-2cd313b3ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test bottle\n",
    "source_dirs_D = [\n",
    "    pathb+'/test/contamination',\n",
    "    pathb+'/test/broken_small',\n",
    "    pathb+'/test/broken_large'# Dossier avec des défauts (MVT-AD)\n",
    " \n",
    "]\n",
    "\n",
    "source_dirs_G = [\n",
    "    pathb+'/test/good',  # Dossier 'good'\n",
    " ]\n",
    "\n",
    "target_dirB = pathb +'/test/test/'  # Dossier cible\n",
    "\n",
    "# Appeler la fonction pour organiser les images\n",
    "reorganize_images_good(source_dirs_G, target_dirB)\n",
    "reorganize_images_default(source_dirs_D, target_dirB)\n",
    "\n",
    "#Création des labels\n",
    "test_filenames_B = os.listdir(target_dirB)\n",
    "test_categories_B = []\n",
    "for filename in test_filenames_B:\n",
    "    category = filename.split('.')[0][:7]\n",
    "    if category == 'default':\n",
    "        test_categories_B.append(1)\n",
    "    else:\n",
    "        test_categories_B.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd810d47-99c9-4646-8778-108bafd3f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test hazelnut\n",
    "source_dirs_D = [\n",
    "    pathh+'/test/crack',\n",
    "    pathh+'/test/cut',\n",
    "    pathh+'/test/print',\n",
    "    pathh+'/test/hole'# Dossier avec des défauts (MVT-AD)\n",
    " \n",
    "]\n",
    "\n",
    "source_dirs_G = [\n",
    "    pathh+'/test/good',  # Dossier 'good'\n",
    " ]\n",
    "\n",
    "target_dirH = pathh +'/test/test'  # Dossier cible\n",
    "\n",
    "# Appeler la fonction pour organiser les images\n",
    "reorganize_images_good(source_dirs_G, target_dirH)\n",
    "reorganize_images_default(source_dirs_D, target_dirH)\n",
    "\n",
    "#Création des labels\n",
    "test_filenames_H = os.listdir(target_dirH)\n",
    "test_categories_H = []\n",
    "for filename in test_filenames_H:\n",
    "    category = filename.split('.')[0][:7]\n",
    "    if category == 'default':\n",
    "        test_categories_H.append(1)\n",
    "    else:\n",
    "        test_categories_H.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "070436c9-8c31-4691-8f85-c3fa90e2820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test capsule\n",
    "source_dirs_D = [\n",
    "    pathc+'/test/crack',\n",
    "    pathc+'/test/faulty_imprint',\n",
    "    pathc+'/test/poke',\n",
    "    pathc+'/test/scratch',\n",
    "    pathc+'/test/squeeze'# Dossier avec des défauts (MVT-AD)\n",
    " \n",
    "]\n",
    "\n",
    "source_dirs_G = [\n",
    "    pathc+'/test/good',  # Dossier 'good'\n",
    " ]\n",
    "\n",
    "target_dirC = pathc +'/test/test'  # Dossier cible\n",
    "\n",
    "# Appeler la fonction pour organiser les images\n",
    "reorganize_images_good(source_dirs_G, target_dirC)\n",
    "reorganize_images_default(source_dirs_D, target_dirC)\n",
    "\n",
    "#Création des labels\n",
    "test_filenames_C = os.listdir(target_dirC)\n",
    "test_categories_C = []\n",
    "for filename in test_filenames_C:\n",
    "    category = filename.split('.')[0][:7]\n",
    "    if category == 'default':\n",
    "        test_categories_C.append(1)\n",
    "    else:\n",
    "        test_categories_C.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc0a1b58-1431-4bfb-bbe5-94789337ec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test toothbrush\n",
    "source_dirs_D = [\n",
    "    patht+'/test/defective'# Dossier avec des défauts (MVT-AD)\n",
    " \n",
    "]\n",
    "\n",
    "source_dirs_G = [\n",
    "    patht+'/test/good',  # Dossier 'good'\n",
    " ]\n",
    "\n",
    "target_dirT = patht +'/test/test'  # Dossier cible\n",
    "\n",
    "# Appeler la fonction pour organiser les images\n",
    "reorganize_images_good(source_dirs_G, target_dirT)\n",
    "reorganize_images_default(source_dirs_D, target_dirT)\n",
    "\n",
    "#Création des labels\n",
    "test_filenames_T = os.listdir(target_dirT)\n",
    "test_categories_T = []\n",
    "for filename in test_filenames_T:\n",
    "    category = filename.split('.')[0][:7]\n",
    "    if category == 'default':\n",
    "        test_categories_T.append(1)\n",
    "    else:\n",
    "        test_categories_T.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a45767a6-2900-4625-bdb9-cd58cf8656e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: './engine_wiring/test/test/good001.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m target_dirW \u001b[38;5;241m=\u001b[39m pathw \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/test/test\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Dossier cible\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Appeler la fonction pour organiser les images\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[43mreorganize_images_good\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_dirs_G\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_dirW\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m reorganize_images_default(source_dirs_D, target_dirW)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#Création des labels\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 25\u001b[0m, in \u001b[0;36mreorganize_images_good\u001b[0;34m(source_dirs, target_dir)\u001b[0m\n\u001b[1;32m     22\u001b[0m target_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(target_dir, new_name)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Copie le fichier vers le dossier cible avec le nouveau nom\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Incrémente le compteur pour le prochain fichier\u001b[39;00m\n\u001b[1;32m     28\u001b[0m count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/shutil.py:417\u001b[0m, in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[1;32m    416\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[0;32m--> 417\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m copymode(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/shutil.py:256\u001b[0m, in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(src, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 256\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[1;32m    257\u001b[0m             \u001b[38;5;66;03m# macOS\u001b[39;00m\n\u001b[1;32m    258\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m _HAS_FCOPYFILE:\n\u001b[1;32m    259\u001b[0m                 \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: './engine_wiring/test/test/good001.png'"
     ]
    }
   ],
   "source": [
    "# Test engine wiring\n",
    "source_dirs_D = [\n",
    "    pathw+'/test/blue_hoop',\n",
    "    pathw+'/test/cardboard',\n",
    "    pathw+'/test/fastening',\n",
    "    pathw+'/test/multiple',\n",
    "    pathw+'/test/obstruction'# Dossier avec des défauts (Auto_VI)\n",
    " \n",
    "]\n",
    "\n",
    "source_dirs_G = [\n",
    "    pathw+'/test/good',  # Dossier 'good'\n",
    " ]\n",
    "\n",
    "target_dirW = pathw +'/test/test'  # Dossier cible\n",
    "\n",
    "# Appeler la fonction pour organiser les images\n",
    "reorganize_images_good(source_dirs_G, target_dirW)\n",
    "reorganize_images_default(source_dirs_D, target_dirW)\n",
    "\n",
    "#Création des labels\n",
    "test_filenames_W = os.listdir(target_dirW)\n",
    "test_categories_W = []\n",
    "for filename in test_filenames_W:\n",
    "    category = filename.split('.')[0][:7]\n",
    "    if category == 'default':\n",
    "        test_categories_W.append(1)\n",
    "    else:\n",
    "        test_categories_W.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7b790db-f71d-47fd-898d-54679c4a9a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 filename  category\n",
      "0    ./MVTec_AD/bottle/train/good/000.png         0\n",
      "1    ./MVTec_AD/bottle/train/good/001.png         0\n",
      "2    ./MVTec_AD/bottle/train/good/002.png         0\n",
      "3    ./MVTec_AD/bottle/train/good/003.png         0\n",
      "4    ./MVTec_AD/bottle/train/good/004.png         0\n",
      "..                                    ...       ...\n",
      "204  ./MVTec_AD/bottle/train/good/204.png         0\n",
      "205  ./MVTec_AD/bottle/train/good/205.png         0\n",
      "206  ./MVTec_AD/bottle/train/good/206.png         0\n",
      "207  ./MVTec_AD/bottle/train/good/207.png         0\n",
      "208  ./MVTec_AD/bottle/train/good/208.png         0\n",
      "\n",
      "[209 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Training images\n",
    "total_train_df_bottle = pd.DataFrame({\n",
    "    'filename': train_filenames_bottle,\n",
    "    'category': train_categories_B\n",
    "})\n",
    "# Test images\n",
    "test_df_bottle = pd.DataFrame({\n",
    "    'filename': test_filenames_B,\n",
    "    'category': test_categories_B\n",
    "})\n",
    "# Mise à jour des chemins dans le DataFrame pour inclure les extensions correctes\n",
    "total_train_df_bottle['filename'] = total_train_df_bottle['filename'].apply(lambda x: os.path.join(pathb+'/train/good', x))\n",
    "test_df_bottle['filename'] = test_df_bottle['filename'].apply(lambda x: os.path.join(target_dirB, x))\n",
    "print(total_train_df_bottle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b347c31-00eb-4f3a-9c3f-4d5278a0954d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   filename  category\n",
      "0    ./MVTec_AD/hazelnut/train/good/000.png         0\n",
      "1    ./MVTec_AD/hazelnut/train/good/001.png         0\n",
      "2    ./MVTec_AD/hazelnut/train/good/002.png         0\n",
      "3    ./MVTec_AD/hazelnut/train/good/003.png         0\n",
      "4    ./MVTec_AD/hazelnut/train/good/004.png         0\n",
      "..                                      ...       ...\n",
      "386  ./MVTec_AD/hazelnut/train/good/386.png         0\n",
      "387  ./MVTec_AD/hazelnut/train/good/387.png         0\n",
      "388  ./MVTec_AD/hazelnut/train/good/388.png         0\n",
      "389  ./MVTec_AD/hazelnut/train/good/389.png         0\n",
      "390  ./MVTec_AD/hazelnut/train/good/390.png         0\n",
      "\n",
      "[391 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Training images\n",
    "total_train_df_hazelnut = pd.DataFrame({\n",
    "    'filename': train_filenames_hazelnut,\n",
    "    'category': train_categories_H\n",
    "})\n",
    "\n",
    "# Test images\n",
    "test_df_hazelnut = pd.DataFrame({\n",
    "    'filename': test_filenames_H,\n",
    "    'category': test_categories_H\n",
    "})\n",
    "\n",
    "\n",
    "# Mise à jour des chemins dans le DataFrame pour inclure les extensions correctes\n",
    "total_train_df_hazelnut['filename'] = total_train_df_hazelnut['filename'].apply(lambda x: os.path.join(pathh+'/train/good', x))\n",
    "test_df_hazelnut['filename'] = test_df_hazelnut['filename'].apply(lambda x: os.path.join(target_dirH, x))\n",
    "print(total_train_df_hazelnut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ac1b029-15c8-4473-9858-b03d38e67dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  filename  category\n",
      "0    ./MVTec_AD/capsule/train/good/000.png         0\n",
      "1    ./MVTec_AD/capsule/train/good/001.png         0\n",
      "2    ./MVTec_AD/capsule/train/good/002.png         0\n",
      "3    ./MVTec_AD/capsule/train/good/003.png         0\n",
      "4    ./MVTec_AD/capsule/train/good/004.png         0\n",
      "..                                     ...       ...\n",
      "214  ./MVTec_AD/capsule/train/good/214.png         0\n",
      "215  ./MVTec_AD/capsule/train/good/215.png         0\n",
      "216  ./MVTec_AD/capsule/train/good/216.png         0\n",
      "217  ./MVTec_AD/capsule/train/good/217.png         0\n",
      "218  ./MVTec_AD/capsule/train/good/218.png         0\n",
      "\n",
      "[219 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Training images\n",
    "total_train_df_capsule = pd.DataFrame({\n",
    "    'filename': train_filenames_capsule,\n",
    "    'category': train_categories_C\n",
    "})\n",
    "\n",
    "# Test images\n",
    "test_df_capsule = pd.DataFrame({\n",
    "    'filename': test_filenames_C,\n",
    "    'category': test_categories_C\n",
    "})\n",
    "\n",
    "# Mise à jour des chemins dans le DataFrame pour inclure les extensions correctes\n",
    "total_train_df_capsule['filename'] = total_train_df_capsule['filename'].apply(lambda x: os.path.join(pathc+'/train/good', x))\n",
    "test_df_capsule['filename'] = test_df_capsule['filename'].apply(lambda x: os.path.join(target_dirC, x))\n",
    "print(total_train_df_capsule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe96b140-c959-4da9-bfcb-fbbe64f62a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    filename  category\n",
      "0   ./MVTec_AD/toothbrush/train/good/000.png         0\n",
      "1   ./MVTec_AD/toothbrush/train/good/001.png         0\n",
      "2   ./MVTec_AD/toothbrush/train/good/002.png         0\n",
      "3   ./MVTec_AD/toothbrush/train/good/003.png         0\n",
      "4   ./MVTec_AD/toothbrush/train/good/004.png         0\n",
      "5   ./MVTec_AD/toothbrush/train/good/005.png         0\n",
      "6   ./MVTec_AD/toothbrush/train/good/006.png         0\n",
      "7   ./MVTec_AD/toothbrush/train/good/007.png         0\n",
      "8   ./MVTec_AD/toothbrush/train/good/008.png         0\n",
      "9   ./MVTec_AD/toothbrush/train/good/009.png         0\n",
      "10  ./MVTec_AD/toothbrush/train/good/010.png         0\n",
      "11  ./MVTec_AD/toothbrush/train/good/011.png         0\n",
      "12  ./MVTec_AD/toothbrush/train/good/012.png         0\n",
      "13  ./MVTec_AD/toothbrush/train/good/013.png         0\n",
      "14  ./MVTec_AD/toothbrush/train/good/014.png         0\n",
      "15  ./MVTec_AD/toothbrush/train/good/015.png         0\n",
      "16  ./MVTec_AD/toothbrush/train/good/016.png         0\n",
      "17  ./MVTec_AD/toothbrush/train/good/017.png         0\n",
      "18  ./MVTec_AD/toothbrush/train/good/018.png         0\n",
      "19  ./MVTec_AD/toothbrush/train/good/019.png         0\n",
      "20  ./MVTec_AD/toothbrush/train/good/020.png         0\n",
      "21  ./MVTec_AD/toothbrush/train/good/021.png         0\n",
      "22  ./MVTec_AD/toothbrush/train/good/022.png         0\n",
      "23  ./MVTec_AD/toothbrush/train/good/023.png         0\n",
      "24  ./MVTec_AD/toothbrush/train/good/024.png         0\n",
      "25  ./MVTec_AD/toothbrush/train/good/025.png         0\n",
      "26  ./MVTec_AD/toothbrush/train/good/026.png         0\n",
      "27  ./MVTec_AD/toothbrush/train/good/027.png         0\n",
      "28  ./MVTec_AD/toothbrush/train/good/028.png         0\n",
      "29  ./MVTec_AD/toothbrush/train/good/029.png         0\n",
      "30  ./MVTec_AD/toothbrush/train/good/030.png         0\n",
      "31  ./MVTec_AD/toothbrush/train/good/031.png         0\n",
      "32  ./MVTec_AD/toothbrush/train/good/032.png         0\n",
      "33  ./MVTec_AD/toothbrush/train/good/033.png         0\n",
      "34  ./MVTec_AD/toothbrush/train/good/034.png         0\n",
      "35  ./MVTec_AD/toothbrush/train/good/035.png         0\n",
      "36  ./MVTec_AD/toothbrush/train/good/036.png         0\n",
      "37  ./MVTec_AD/toothbrush/train/good/037.png         0\n",
      "38  ./MVTec_AD/toothbrush/train/good/038.png         0\n",
      "39  ./MVTec_AD/toothbrush/train/good/039.png         0\n",
      "40  ./MVTec_AD/toothbrush/train/good/040.png         0\n",
      "41  ./MVTec_AD/toothbrush/train/good/041.png         0\n",
      "42  ./MVTec_AD/toothbrush/train/good/042.png         0\n",
      "43  ./MVTec_AD/toothbrush/train/good/043.png         0\n",
      "44  ./MVTec_AD/toothbrush/train/good/044.png         0\n",
      "45  ./MVTec_AD/toothbrush/train/good/045.png         0\n",
      "46  ./MVTec_AD/toothbrush/train/good/046.png         0\n",
      "47  ./MVTec_AD/toothbrush/train/good/047.png         0\n",
      "48  ./MVTec_AD/toothbrush/train/good/048.png         0\n",
      "49  ./MVTec_AD/toothbrush/train/good/049.png         0\n",
      "50  ./MVTec_AD/toothbrush/train/good/050.png         0\n",
      "51  ./MVTec_AD/toothbrush/train/good/051.png         0\n",
      "52  ./MVTec_AD/toothbrush/train/good/052.png         0\n",
      "53  ./MVTec_AD/toothbrush/train/good/053.png         0\n",
      "54  ./MVTec_AD/toothbrush/train/good/054.png         0\n",
      "55  ./MVTec_AD/toothbrush/train/good/055.png         0\n",
      "56  ./MVTec_AD/toothbrush/train/good/056.png         0\n",
      "57  ./MVTec_AD/toothbrush/train/good/057.png         0\n",
      "58  ./MVTec_AD/toothbrush/train/good/058.png         0\n",
      "59  ./MVTec_AD/toothbrush/train/good/059.png         0\n"
     ]
    }
   ],
   "source": [
    "# Training images\n",
    "total_train_df_toothbrush = pd.DataFrame({\n",
    "    'filename': train_filenames_toothbrush,\n",
    "    'category': train_categories_T\n",
    "})\n",
    "\n",
    "# Test images\n",
    "test_df_toothbrush = pd.DataFrame({\n",
    "    'filename': test_filenames_T,\n",
    "    'category': test_categories_T\n",
    "})\n",
    "\n",
    "\n",
    "# Mise à jour des chemins dans le DataFrame pour inclure les extensions correctes\n",
    "total_train_df_toothbrush['filename'] = total_train_df_toothbrush['filename'].apply(lambda x: os.path.join(patht+'/train/good', x))\n",
    "test_df_toothbrush['filename'] = test_df_toothbrush['filename'].apply(lambda x: os.path.join(target_dirT, x))\n",
    "print(total_train_df_toothbrush)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6464abce-166c-4964-976e-b1bc92dcb475",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_filenames_W' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m total_train_df_W \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m: train_filenames_W,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m: train_categories_W\n\u001b[1;32m      5\u001b[0m })\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Test images\u001b[39;00m\n\u001b[1;32m      8\u001b[0m test_df_W \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mtest_filenames_W\u001b[49m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m: test_categories_W\n\u001b[1;32m     11\u001b[0m })\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Mise à jour des chemins dans le DataFrame pour inclure les extensions correctes\u001b[39;00m\n\u001b[1;32m     15\u001b[0m total_train_df_W[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m total_train_df_W[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(pathw\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/train/good\u001b[39m\u001b[38;5;124m'\u001b[39m, x))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_filenames_W' is not defined"
     ]
    }
   ],
   "source": [
    "# Training images\n",
    "total_train_df_W = pd.DataFrame({\n",
    "    'filename': train_filenames_W,\n",
    "    'category': train_categories_W\n",
    "})\n",
    "\n",
    "# Test images\n",
    "test_df_W = pd.DataFrame({\n",
    "    'filename': test_filenames_W,\n",
    "    'category': test_categories_W\n",
    "})\n",
    "\n",
    "\n",
    "# Mise à jour des chemins dans le DataFrame pour inclure les extensions correctes\n",
    "total_train_df_W['filename'] = total_train_df_W['filename'].apply(lambda x: os.path.join(pathw+'/train/good', x))\n",
    "test_df_W['filename'] = test_df_W['filename'].apply(lambda x: os.path.join(target_dirW, x))\n",
    "print(total_train_df_W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1045a1-28ef-4273-9533-49edf99e9994",
   "metadata": {},
   "source": [
    "# I - Partie 1 : Train SSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7dad0485-7bf4-4b81-81bf-40f90833cdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels=3, latent_dim=128):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=4, stride=2, padding=1),  # 32x32 -> 16x16\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),  # 16x16 -> 8x8\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),  # 8x8 -> 4x4\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, latent_dim, kernel_size=4, stride=2, padding=1),  # 4x4 -> 2x2\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=128, out_channels=3):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim, 256, kernel_size=4, stride=2, padding=1),  # 2x2 -> 4x4\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),  # 4x4 -> 8x8\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),  # 8x8 -> 16x16\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, out_channels, kernel_size=4, stride=2, padding=1),  # 16x16 -> 32x32\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71026d8c-f1af-4b09-834c-db25147d06eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "# Définir un Dataset personnalisé\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): DataFrame contenant les colonnes ['path', 'label'].\n",
    "            transform (callable, optional): Transformations à appliquer sur les images.\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx, 0]\n",
    "        label = self.dataframe.iloc[idx, 1]\n",
    "\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du chargement de l'image {img_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Exemple d'utilisation\n",
    "def create_dataloader(dataframe, batch_size=128, image_size=(32, 32), shuffle=True):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    dataset = CustomDataset(dataframe, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=2)\n",
    "    return dataloader\n",
    "\n",
    "# Exemple de DataFrame\n",
    "\n",
    "# Création des DataLoaders pour \"bottle\"\n",
    "dataloader_train_b = create_dataloader(total_train_df_bottle, batch_size=1)\n",
    "dataloader_test_b = create_dataloader(test_df_bottle, batch_size=1)\n",
    "\n",
    "# Création des DataLoaders pour \"hazelnut\"\n",
    "dataloader_train_h = create_dataloader(total_train_df_hazelnut, batch_size=1)\n",
    "dataloader_test_h = create_dataloader(test_df_hazelnut, batch_size=1)\n",
    "\n",
    "# Création des DataLoaders pour \"capsule\"\n",
    "dataloader_train_c = create_dataloader(total_train_df_capsule, batch_size=1)\n",
    "dataloader_test_c = create_dataloader(test_df_capsule, batch_size=1)\n",
    "\n",
    "# Création des DataLoaders pour \"toothbrush\"\n",
    "dataloader_train_t = create_dataloader(total_train_df_toothbrush, batch_size=1)\n",
    "dataloader_test_t = create_dataloader(test_df_toothbrush, batch_size=1)\n",
    "\n",
    "# Création des DataLoaders pour EW (w)\n",
    "#dataloader_train_w = create_dataloader(total_train_df_W, batch_size=1)\n",
    "#dataloader_test_w = create_dataloader(test_df_W, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9daea2ea-b76a-404c-8944-6f74e66f2e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ssl_model(model, \n",
    "                    train_loader, \n",
    "                    test_loader, \n",
    "                    criterion,\n",
    "                    optimizer,\n",
    "                    device=device,\n",
    "                    epochs=5):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.to(device)\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for images, _ in train_loader:\n",
    "            images = images.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output, _ = model(images)\n",
    "            loss = criterion(output, images)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for images, _ in test_loader:\n",
    "                images = images.to(device)\n",
    "                output, _ = model(images)\n",
    "                val_loss = criterion(output, images)\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(test_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Avg Val Loss: {avg_val_loss:.4f}\")\n",
    "    \n",
    "    return model.encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8265dac6-f87a-4bcb-ae80-3c9262c3b6d2",
   "metadata": {},
   "source": [
    "## Pretext tasks 1 : colorizing model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77381af6-697c-46b6-887c-9833361a06be",
   "metadata": {},
   "source": [
    "Explications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "85e09772-6652-48e8-99a3-915690231ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorizationModel(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super(ColorizationModel, self).__init__()\n",
    "        self.encoder = Encoder(latent_dim=latent_dim, in_channels=1)  # Input grayscale\n",
    "        self.decoder = Decoder(latent_dim=latent_dim, out_channels=3)  # Predict RGB\n",
    "\n",
    "    def forward(self, x):\n",
    "        grayscale_x = transforms.Grayscale(num_output_channels=1)(x)  # Convert RGB to Grayscale\n",
    "        z = self.encoder(grayscale_x)\n",
    "        return self.decoder(z), grayscale_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815dba8b-a033-49bf-870c-1fd34c05cb35",
   "metadata": {},
   "source": [
    "### Sur MVTec_AD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f172644-8c35-4f0f-830a-b9a1ef8586a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training bottle\n",
      "Epoch 1/5, Train Loss: 0.0080, Avg Val Loss: 0.0018\n",
      "Epoch 2/5, Train Loss: 0.0009, Avg Val Loss: 0.0021\n",
      "Epoch 3/5, Train Loss: 0.0009, Avg Val Loss: 0.0017\n",
      "Epoch 4/5, Train Loss: 0.0008, Avg Val Loss: 0.0018\n",
      "Epoch 5/5, Train Loss: 0.0008, Avg Val Loss: 0.0017\n"
     ]
    }
   ],
   "source": [
    "print(\"Training bottle\")\n",
    "# Modèle de colorisation\n",
    "colorization_model_bottle = ColorizationModel(latent_dim=128)  # Instantiate the colorization model\n",
    "\n",
    "# Pré-entrainement pour \"bottle\"\n",
    "colorization_model_bottle = train_ssl_model(\n",
    "    colorization_model_bottle,\n",
    "    dataloader_train_b,\n",
    "    dataloader_test_b,\n",
    "    criterion=nn.MSELoss(),\n",
    "    optimizer=optim.Adam(colorization_model_bottle.parameters(), lr=0.001)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bc4733c8-8381-45a4-8551-7b4628c51604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training hazelnut\n",
      "Epoch 1/5, Train Loss: 0.0053, Avg Val Loss: 0.0018\n",
      "Epoch 2/5, Train Loss: 0.0018, Avg Val Loss: 0.0019\n",
      "Epoch 3/5, Train Loss: 0.0018, Avg Val Loss: 0.0020\n",
      "Epoch 4/5, Train Loss: 0.0016, Avg Val Loss: 0.0019\n",
      "Epoch 5/5, Train Loss: 0.0012, Avg Val Loss: 0.0013\n",
      "Training capsule\n",
      "Epoch 1/5, Train Loss: 0.0049, Avg Val Loss: 0.0013\n",
      "Epoch 2/5, Train Loss: 0.0010, Avg Val Loss: 0.0006\n",
      "Epoch 3/5, Train Loss: 0.0007, Avg Val Loss: 0.0011\n",
      "Epoch 4/5, Train Loss: 0.0007, Avg Val Loss: 0.0006\n",
      "Epoch 5/5, Train Loss: 0.0006, Avg Val Loss: 0.0008\n",
      "Training toothbrush\n",
      "Epoch 1/5, Train Loss: 0.0210, Avg Val Loss: 0.0036\n",
      "Epoch 2/5, Train Loss: 0.0026, Avg Val Loss: 0.0023\n",
      "Epoch 3/5, Train Loss: 0.0020, Avg Val Loss: 0.0019\n",
      "Epoch 4/5, Train Loss: 0.0017, Avg Val Loss: 0.0018\n",
      "Epoch 5/5, Train Loss: 0.0016, Avg Val Loss: 0.0018\n"
     ]
    }
   ],
   "source": [
    "print(\"Training hazelnut\")\n",
    "colorization_model_hazelnut = ColorizationModel(latent_dim=128)  # Instantiate the colorization model\n",
    "\n",
    "# Pré-entrainement pour \"hazelnut\"\n",
    "colorization_encoder_h = train_ssl_model(\n",
    "    colorization_model_hazelnut,\n",
    "    dataloader_train_h,\n",
    "    dataloader_test_h,\n",
    "    criterion=nn.MSELoss(),\n",
    "    optimizer=optim.Adam(colorization_model_hazelnut.parameters(), lr=0.001)\n",
    ")\n",
    "\n",
    "print(\"Training capsule\")\n",
    "colorization_model_capsule = ColorizationModel(latent_dim=128)  # Instantiate the colorization model\n",
    "\n",
    "# Pré-entrainement pour \"capsule\"\n",
    "colorization_encoder_c = train_ssl_model(\n",
    "    colorization_model_capsule,\n",
    "    dataloader_train_c,\n",
    "    dataloader_test_c,\n",
    "    criterion=nn.MSELoss(),\n",
    "    optimizer=optim.Adam(colorization_model_capsule.parameters(), lr=0.001)\n",
    ")\n",
    "\n",
    "print(\"Training toothbrush\")\n",
    "colorization_model_toothbrush = ColorizationModel(latent_dim=128)  # Instantiate the colorization model\n",
    "\n",
    "# Pré-entrainement pour \"toothbrush\"\n",
    "colorization_encoder_t = train_ssl_model(\n",
    "    colorization_model_toothbrush,\n",
    "    dataloader_train_t,\n",
    "    dataloader_test_t,\n",
    "    criterion=nn.MSELoss(),\n",
    "    optimizer=optim.Adam(colorization_model_toothbrush.parameters(), lr=0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862d40fb-c4d7-45dd-9298-7606f4d18267",
   "metadata": {},
   "source": [
    "Interprétations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4a55c437-e854-417c-98ba-2fa54d1f168a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 1, 4, 4], expected input[5, 3, 32, 32] to have 1 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Visualize colorization on random test images\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m \u001b[43mvisualize_reconstructions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolorization_model_bottle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_test_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[50], line 24\u001b[0m, in \u001b[0;36mvisualize_reconstructions\u001b[0;34m(model, data_loader, device, num_images)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Run the grayscale images through the colorization model\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 24\u001b[0m     reconstructed_images, perturbed_images \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Move images back to CPU for visualization\u001b[39;00m\n\u001b[1;32m     27\u001b[0m images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mcpu()\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[42], line 16\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/torch/nn/modules/conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/torch/nn/modules/conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 1, 4, 4], expected input[5, 3, 32, 32] to have 1 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Visualize colorization on random test images\n",
    "\n",
    "def visualize_reconstructions(model, data_loader, device, num_images=5):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Convert the DataLoader to a list to randomly sample images\n",
    "    dataset = list(data_loader.dataset)\n",
    "\n",
    "    # Randomly select `num_images` images from the dataset\n",
    "    random_indices = random.sample(range(len(dataset)), num_images)\n",
    "    random_images = [dataset[i][0] for i in random_indices]  # Extract only the images, ignoring labels\n",
    "\n",
    "    # Stack the images into a batch\n",
    "    images = torch.stack(random_images)\n",
    "\n",
    "    # Move images to the specified device\n",
    "    images = images.to(device)\n",
    "    \n",
    "    # Run the grayscale images through the colorization model\n",
    "    with torch.no_grad():\n",
    "        reconstructed_images, perturbed_images = model(images)\n",
    "    \n",
    "    # Move images back to CPU for visualization\n",
    "    images = images.cpu()\n",
    "    reconstructed_images = reconstructed_images.cpu()\n",
    "    perturbed_images = perturbed_images.cpu()\n",
    "    \n",
    "    # Plot the grayscale, ground truth, and colorized images\n",
    "    fig, axes = plt.subplots(num_images, 3, figsize=(10, num_images * 4))\n",
    "    for i in range(num_images):\n",
    "        # Grayscale input\n",
    "        axes[i, 0].imshow(perturbed_images[i].permute(1, 2, 0).squeeze(), cmap='gray')\n",
    "        axes[i, 0].set_title(\"Grayscale Input\")\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Ground truth (original RGB image)\n",
    "        axes[i, 1].imshow(images[i].permute(1, 2, 0))\n",
    "        axes[i, 1].set_title(\"Ground Truth (RGB)\")\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # Colorized output from the model\n",
    "        axes[i, 2].imshow(reconstructed_images[i].permute(1, 2, 0))\n",
    "        axes[i, 2].set_title(\"Colorized Output\")\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize colorization on random test images\n",
    "visualize_reconstructions(colorization_model_bottle, dataloader_test_b, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf12b90-cee3-4934-89e7-75e6c12b404c",
   "metadata": {},
   "source": [
    "### Sur Auto_VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "892120c7-9682-4793-8665-bbb5efa010a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 0.0251, Avg Val Loss: 0.0196\n",
      "Epoch 2/5, Train Loss: 0.0172, Avg Val Loss: 0.0172\n",
      "Epoch 3/5, Train Loss: 0.0143, Avg Val Loss: 0.0157\n",
      "Epoch 4/5, Train Loss: 0.0127, Avg Val Loss: 0.0149\n",
      "Epoch 5/5, Train Loss: 0.0118, Avg Val Loss: 0.0142\n"
     ]
    }
   ],
   "source": [
    "colorization_model_w = ColorizationModel(latent_dim=128)  # Instantiate the colorization model\n",
    "\n",
    "# Pré-entrainement pour \"engine wiring\" (w)\n",
    "colorization_encoder_w = train_ssl_model(\n",
    "    colorization_model_w,\n",
    "    dataloader_train_w,\n",
    "    dataloader_test_w,\n",
    "    criterion=nn.MSELoss(),\n",
    "    optimizer=optim.Adam(colorization_model_w.parameters(), lr=0.001)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c1f1f3-ce1a-4663-88c2-72f3f17a0706",
   "metadata": {},
   "source": [
    "Interprétations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6935ad96-ccfb-47b9-a8a4-a49ccc0669c6",
   "metadata": {},
   "source": [
    "## Pretext tasks 2 : inpainting model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92683353-9d69-4f55-8764-50c410a93c24",
   "metadata": {},
   "source": [
    "### Sur MVTec_AD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d5c26e-bc14-4695-a76f-6d03a362525e",
   "metadata": {},
   "source": [
    "### Sur Auto_VI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc405d94-316f-41b3-b6b6-91eabd31fe35",
   "metadata": {},
   "source": [
    "## Pretext tasks 3 : masked autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207472ec-6a77-4399-af63-eef90a0398d9",
   "metadata": {},
   "source": [
    "### Sur MVTec_AD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cde372-f6f8-468e-80d3-8077cb8d90fc",
   "metadata": {},
   "source": [
    "### Sur Auto_VI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf23d06-0082-4dd5-88bc-05e6ec6ca429",
   "metadata": {},
   "source": [
    "# II - Partie 2 :\n",
    "Use the model loss as an anomaly score and evaluate the anomaly score’s\n",
    "discriminative power by plotting the ROC curve and the AUROC metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a50aca8-705c-4403-a94a-1a9706dcfda1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
